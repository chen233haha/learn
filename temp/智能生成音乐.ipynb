{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "用训练好的神经网络模型参数来作曲\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from ulit import *\n",
    "from network import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以之前训练所得的最佳参数来生成音乐\n",
    "def generate():\n",
    "    # 加载用于训练神经网络的音乐数据\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # 得到所有音调的名字\n",
    "    pitch_names = sorted(set(item for item in notes))\n",
    "\n",
    "    # 得到所有不重复（因为用了set）的音调数目\n",
    "    num_pitch = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences(notes, pitch_names, num_pitch)\n",
    "\n",
    "    # 载入之前训练时最好的参数文件（最好用 loss 最小 的那一个参数文件，\n",
    "    # 记得要把它的名字改成 best-weights.hdf5 ），来生成神经网络模型\n",
    "    model = network_model(normalized_input, num_pitch, \"best-weights.hdf5\")\n",
    "\n",
    "    # 用神经网络来生成音乐数据\n",
    "    prediction = generate_notes(model, network_input, pitch_names, num_pitch)\n",
    "\n",
    "    # 用预测的音乐数据生成 MIDI 文件，再转换成 MP3\n",
    "    create_music(prediction)\n",
    "\n",
    "\n",
    "def prepare_sequences(notes, pitch_names, num_pitch):\n",
    "    \"\"\"\n",
    "    为神经网络准备好供训练的序列\n",
    "    \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # 创建一个字典，用于映射 音调 和 整数\n",
    "    pitch_to_int = dict((pitch, num) for num, pitch in enumerate(pitch_names))\n",
    "\n",
    "    # 创建神经网络的输入序列和输出序列\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i: i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "\n",
    "        network_input.append([pitch_to_int[char] for char in sequence_in])\n",
    "        network_output.append(pitch_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # 将输入的形状转换成神经网络模型可以接受的\n",
    "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "    # 将 输入 标准化/归一化\n",
    "    # 归一话可以让之后的优化器（optimizer）能够更快更好地找到误差最小值\n",
    "    normalized_input = normalized_input / float(num_pitch)\n",
    "\n",
    "    return network_input, normalized_input\n",
    "\n",
    "\n",
    "def generate_notes(model, network_input, pitch_names, num_pitch):\n",
    "    \"\"\"\n",
    "    基于一序列音符，用神经网络来生成新的音符\n",
    "    \"\"\"\n",
    "\n",
    "    # 从输入里随机选择一个序列，作为\"预测\"/生成的音乐的起始点\n",
    "    start = np.random.randint(0, len(network_input) - 1)\n",
    "\n",
    "    # 创建一个字典，用于映射 整数 和 音调\n",
    "    int_to_pitch = dict((num, pitch) for num, pitch in enumerate(pitch_names))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "\n",
    "    # 神经网络实际生成的音调\n",
    "    prediction_output = []\n",
    "\n",
    "    # 生成 700 个 音符/音调\n",
    "    for note_index in range(700):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        # 输入 归一化\n",
    "        prediction_input = prediction_input / float(num_pitch)\n",
    "\n",
    "        # 用载入了训练所得最佳参数文件的神经网络来 预测/生成 新的音调\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        # argmax 取最大的那个维度（类似 One-Hot 独热码）\n",
    "        index = np.argmax(prediction)\n",
    "\n",
    "        # 将 整数 转成 音调\n",
    "        result = int_to_pitch[index]\n",
    "\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        # 往后移动\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cc/.local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1456: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/cc/.local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "将 output.mid 转换为 MP3\n",
      "转换完毕. 生成的文件是 output.mp3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
